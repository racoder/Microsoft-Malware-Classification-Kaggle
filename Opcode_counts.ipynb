{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pickle\n",
    "import re\n",
    "import os, os.path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_path='dict_full' #where to store the output\n",
    "label_csv_path='./trainLabels.csv' #path to csv file mapping filenames to labels\n",
    "data_path = 'train/' #path to the data\n",
    "\n",
    "dump_path = 'new_opcodes.txt'\n",
    "unpickled_file=open(dump_path,'rb')\n",
    "unpickled_dict=pickle.load(unpickled_file)\n",
    "raw_opcode_list=unpickled_dict.keys() #list of opcodes to filter\n",
    "#raw_opcode_list=['mov','add','sub','imul'] #list of opcodes to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opcode_dict_l=list()\n",
    "for i in range(0,9):\n",
    "    opcode_dict=dict()\n",
    "    for item in raw_opcode_list:\n",
    "        formatted_opcode=' '+item+' '\n",
    "        opcode_dict[formatted_opcode]=0\n",
    "    opcode_dict_l.append(opcode_dict)\n",
    "\n",
    "def count_opcodes(directory_path,filename):\n",
    "    #byte_limit=100\n",
    "    new_opcode_dict=dict()\n",
    "    # print opcode_dict\n",
    "    for key in opcode_dict.keys():\n",
    "        new_opcode_dict[key] = 0\n",
    "    try:\n",
    "        path=directory_path+filename\n",
    "        openfile = io.open(path,'r',encoding='latin-1')\n",
    "        #openfile = open(path,'rb')\n",
    "        l_lines=openfile.readlines()\n",
    "        count=0\n",
    "        lc=0\n",
    "        for line in l_lines:\n",
    "            opcode_group = re.search('\\s\\s\\s[a-z][a-z]+\\s\\s\\s',line)\n",
    "            if opcode_group:\n",
    "                opcode = opcode_group.group()\n",
    "                opcode.strip()\n",
    "                if opcode in new_opcode_dict.keys():\n",
    "                            new_opcode_dict[opcode] = 1\n",
    "                if opcode not in d:\n",
    "                    d[opcode]=1\n",
    "                else:\n",
    "                    d[opcode]+=1\n",
    "                for opcode in opcode_dict.keys():\n",
    "                    #match_opcode=None\n",
    "                    match_opcode=re.search(opcode,line)\n",
    "                    if match_opcode:\n",
    "                    #print (match.group())\n",
    "                       # filename_key= filename[:-4]\n",
    "                        if opcode not in new_opcode_dict.keys():\n",
    "                            new_opcode_dict[opcode] = 1\n",
    "                        else:\n",
    "                            new_opcode_dict[opcode] += 1\n",
    "                        #opcode_dict_l[label_d[filename_key]-1][opcode]+=1\n",
    "                        break\n",
    "        openfile.close()\n",
    "    except IOError:\n",
    "        print (\"Could not open file!\")\n",
    "    total=1\n",
    "    '''\n",
    "    for opcode in new_opcode_dict.keys():\n",
    "        total+=new_opcode_dict[opcode]\n",
    "    # print (new_opcode_dict)\n",
    "    for opcode in new_opcode_dict.keys():\n",
    "        new_opcode_dict[opcode] = new_opcode_dict[opcode]/total\n",
    "    #print new_opcode_dict\n",
    "    '''\n",
    "    return new_opcode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 I am alive\n",
      "1 I am alive\n",
      "2"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "dt = np.dtype([('Id', 'a30'), ('Class', 'u2')])\n",
    "data = np.loadtxt('trainLabels.csv', skiprows=1, delimiter = ',', dtype=dt)\n",
    "\n",
    "X = np.zeros((data.shape[0], len(raw_opcode_list)))\n",
    "Y = data['Class']\n",
    "\n",
    "for i, (Id, Class) in enumerate(data):\n",
    "    #print \"iterating\"\n",
    "    asmFile = Id[1:-1]+'.asm'\n",
    "    countDict = count_opcodes('train/',asmFile)\n",
    "    j = 0\n",
    "    for key in countDict.keys():\n",
    "        #print countDict[key]\n",
    "        X[i][j] = countDict[key]\n",
    "        j = j + 1\n",
    "    print i, \"I am alive\"\n",
    "    if i>2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainCV(X,y, clf):\n",
    " \n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=3,shuffle=True)\n",
    "    #y_prob = np.zeros((len(y),3))\n",
    "    y_pred = np.zeros(len(y))\n",
    "\n",
    "    avLoss = 0\n",
    "     \n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        #print X_train\n",
    "        #print \"test\", test_index\n",
    "        y_train = y[train_index]\n",
    " \n",
    "        clf.fit(X_train,y_train)\n",
    "    #print clf.get_params()\n",
    "    print clf.coef_, clf.intercept_\n",
    "    predictions = clf.predict_proba(X_test)\n",
    "    #print \"predictions\", predictions\n",
    "    #y_prob[test_index] = predictions\n",
    "    y_pred[test_index] = clf.predict(X_test)\n",
    "    y_test = y[test_index]\n",
    "    #print type(y_test), type(y_pred[test_index])\n",
    "    logLoss = log_loss(y_test, predictions)\n",
    "    print 'Log loss is %.3f' % logLoss\n",
    "    avLoss = avLoss + logLoss\n",
    "    avLoss = avLoss/len(kf)\n",
    "    print 'Average Log Loss is %.3f' %avLoss\n",
    "    return avLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cList = [1e3,1e2,10,1,0.1,0.01,0.001]\n",
    "minError = 100\n",
    "minC = cList[0]\n",
    "for cVal in cList:\n",
    "    clf = LogisticRegression(C=cVal)\n",
    "    error = trainCV(X,Y,clf)\n",
    "    print 'current Log loss is %.3f' % error\n",
    "    print 'current C is %.3f' % cVal\n",
    "    if error < minError:\n",
    "        minError = error\n",
    "        minC = cVal\n",
    "print 'Min log loss is %.3f' % minError\n",
    "print 'Min C is %.3f' % minC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
